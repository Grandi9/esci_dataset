{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow\n",
    "#!pip install chromadb\n",
    "#!pip install sentence_transformers\n",
    "#!pip install tfidf_index\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install datasets\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20845d",
   "metadata": {},
   "source": [
    "# Step - 1 Load the data\n",
    "\n",
    "1a - Filtered for task-1, and 'us' and 'e' esci (exact, substitute, complement, and irrelevant)\n",
    "\n",
    "1b - Merge the Datasets using product_locale and product_id (connects each query/label pair to its corresponding product information)\n",
    "\n",
    "1c - Filtering the large merged DataFrame down to the required data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "df_examples =pd.read_parquet(r'C:\\Users\\saiasg\\OneDrive - kochind.com\\Desktop\\Projects\\esci\\esci_dataset\\dataset\\shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet(r'C:\\Users\\saiasg\\OneDrive - kochind.com\\Desktop\\Projects\\esci\\esci_dataset\\dataset\\shopping_queries_dataset_products.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "# filter for Task 1 (using the 'small_version' flag)\n",
    "df_task_1 = df_merged[df_merged[\"small_version\"] == 1]\n",
    "\n",
    "# filter for the training set\n",
    "df_task_1_train = df_task_1[df_task_1[\"split\"] == \"train\"]\n",
    "\n",
    "# applying filters for 'us' locale and 'E' label\n",
    "final_training_data = df_task_1_train[\n",
    "    (df_task_1_train[\"product_locale\"] == \"us\") &\n",
    "    (df_task_1_train[\"esci_label\"] == \"E\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_training_data\n",
    "final_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170f084",
   "metadata": {},
   "source": [
    "# Step - 2: Create sample dataset\n",
    "\n",
    "Task: Create a sample dataset consisting of approximately 500 rows with\n",
    "around 50 unique queries from point number 1. If this doesn't yield\n",
    "the desired dataset, you may use the following steps to generate the\n",
    "sample dataset.\n",
    "\n",
    "a. Determine a random sample of 50 unique queries from the\n",
    "dataset derived from point number 1.\n",
    "\n",
    "b. Filter the dataset derived from point number 1 to contain only\n",
    "the unique queries from point number 2.a.\n",
    "\n",
    "c. Create a sample dataset of 500 rows from the dataset derived\n",
    "from point number 2.b\n",
    "\n",
    "Approach:\n",
    "\n",
    "Creating a 500-row sample from the training data, centered on 50 unique queries.\n",
    "\n",
    "2a: Random sampling of rows\n",
    "\n",
    "2b: (Simple Random Sampling), select 50 unique queries and then sample row\n",
    "\n",
    "2c: Stratified sampling with around 60 unique queries to find 50 that yield a sample close to 500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = final_training_data.reset_index(drop=True)\n",
    "print(f\"1. Total rows in dataset: {len(df_full)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429274c",
   "metadata": {},
   "source": [
    "#### 2a: Random sampling of rows - Basic barebones\n",
    "\n",
    "We just randomly grab 500 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6498d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "RANDOM_STATE = 42\n",
    "TARGET_QUERIES = 50\n",
    "TARGET_ROWS = 500\n",
    "\n",
    "df_full = final_training_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n--- Step 2a: Simple Random Sample ---\")\n",
    "sample_2a = df_full.sample(n=TARGET_ROWS, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "final_unique_2a = sample_2a['query'].nunique()\n",
    "\n",
    "print(f\"Result: {final_unique_2a} unique queries in the sample.\")\n",
    "print(\"\\nSample Head:\")\n",
    "display(sample_2a[['query', 'product_title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39183541",
   "metadata": {},
   "source": [
    "#### Step 2b: Sample from Filtered Queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df69b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. randomly select 50 unique queries\n",
    "unique_queries_2b = df_full['query'].unique()\n",
    "if len(unique_queries_2b) < TARGET_QUERIES:\n",
    "    sample_queries_2b = pd.Series(unique_queries_2b)\n",
    "else:\n",
    "    sample_queries_2b = pd.Series(unique_queries_2b).sample(n=TARGET_QUERIES, random_state=RANDOM_STATE)\n",
    "\n",
    "# 2. filter master set to products matching these queries\n",
    "df_filtered_2b = df_full[df_full['query'].isin(sample_queries_2b)].reset_index(drop=True)\n",
    "total_rows_for_queries_2b = len(df_filtered_2b)\n",
    "\n",
    "print(f\"-> selected {len(sample_queries_2b)} unique queries.\")\n",
    "print(f\"-> total rows available after filtering: {total_rows_for_queries_2b}\")\n",
    "\n",
    "# 3. sample 500 rows from filtered dataset\n",
    "if total_rows_for_queries_2b <= TARGET_ROWS:\n",
    "    sample_2b = df_filtered_2b.copy()\n",
    "    print(f\"filtered set too small ({total_rows_for_queries_2b} rows), using all available.\")\n",
    "else:\n",
    "    sample_2b = df_filtered_2b.sample(n=TARGET_ROWS, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "    print(f\"took random sample of {len(sample_2b)} rows from filtered dataset.\")\n",
    "\n",
    "# 4. final results\n",
    "final_unique_2b = sample_2b['query'].nunique()\n",
    "print(f\"result: {len(sample_2b)} rows and {final_unique_2b} unique queries in sample.\")\n",
    "\n",
    "print(\"\\nSample 2b Head:\")\n",
    "display(sample_2b[['query', 'product_title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785e03e",
   "metadata": {},
   "source": [
    "#### 2c Stratified sampling\n",
    "\n",
    "Using this approach to select queries by row count to get more sample diversity\n",
    "\n",
    "This method ensures representation from all queries, and also high-frequency queries, using this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Step 2c: Stratified Sampling for Target Rows and Queries ---\")\n",
    "\n",
    "TARGET_QUERIES_2c = 70 # aiming for higher number of unique queries initially\n",
    "\n",
    "# 1. randomly selecting 70 unique queries\n",
    "unique_queries_full = df_full['query'].unique()\n",
    "if len(unique_queries_full) < TARGET_QUERIES_2c:\n",
    "    potential_sample_queries = pd.Series(unique_queries_full)\n",
    "    print(f\"only {len(unique_queries_full)} unique queries available, using all.\")\n",
    "else:\n",
    "    potential_sample_queries = pd.Series(unique_queries_full).sample(n=TARGET_QUERIES_2c, random_state=RANDOM_STATE)\n",
    "    print(f\"randomly selected {len(potential_sample_queries)} potential unique queries.\")\n",
    "\n",
    "# 2. filtering rows associated with selected queries\n",
    "df_potential_queries = df_full[df_full['query'].isin(potential_sample_queries)].reset_index(drop=True)\n",
    "print(f\"filtered down to {len(df_potential_queries)} rows associated with these queries.\")\n",
    "\n",
    "# 3. calculate rows per query\n",
    "query_row_counts = df_potential_queries.groupby('query').size().sort_values(ascending=False)\n",
    "print(\"\\nRow counts for potential queries:\")\n",
    "display(query_row_counts.head())\n",
    "\n",
    "# 4. select top 50 queries by row count\n",
    "selected_queries_2c = []\n",
    "current_row_count = 0\n",
    "for query, count in query_row_counts.items():\n",
    "    if len(selected_queries_2c) < 50:\n",
    "         selected_queries_2c.append(query)\n",
    "         current_row_count += count\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# ensure we have exactly 50 queries if available\n",
    "if len(selected_queries_2c) < 50 and len(potential_sample_queries) >= 50:\n",
    "     print(f\"warning: could only select {len(selected_queries_2c)} queries.\")\n",
    "elif len(selected_queries_2c) == 50:\n",
    "     print(f\"\\nselected 50 queries that yield {current_row_count} rows.\")\n",
    "\n",
    "# 5. filter to final 50 queries\n",
    "df_final_50_queries = df_potential_queries[df_potential_queries['query'].isin(selected_queries_2c)].reset_index(drop=True)\n",
    "\n",
    "# 6. determine final sample based on row count\n",
    "if len(df_final_50_queries) == TARGET_ROWS:\n",
    "    sample_2c = df_final_50_queries.copy()\n",
    "    print(f\"final filtered set has exactly {TARGET_ROWS} rows.\")\n",
    "elif len(df_final_50_queries) < TARGET_ROWS:\n",
    "    sample_2c = df_final_50_queries.copy()\n",
    "    print(f\"final filtered set has {len(df_final_50_queries)} rows, using all available.\")\n",
    "else:\n",
    "    sample_2c = df_final_50_queries.sample(n=TARGET_ROWS, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "    print(f\"final filtered set has {len(df_final_50_queries)} rows, taking random sample of {TARGET_ROWS}.\")\n",
    "\n",
    "# 7. final results\n",
    "final_unique_2c = sample_2c['query'].nunique()\n",
    "print(f\"\\nfinal sample (2c) result: {len(sample_2c)} rows and {final_unique_2c} unique queries.\")\n",
    "\n",
    "print(\"\\nFinal Sample (2c) Head:\")\n",
    "display(sample_2c[['query', 'product_title', 'esci_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sample_2c DataFrame to a CSV file\n",
    "sample_2c.to_csv(r'C:\\Users\\saiasg\\OneDrive - kochind.com\\Desktop\\Projects\\esci\\esci_dataset\\sample_2c_full_data.csv', index=False)\n",
    "\n",
    "sample_2c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Queries in sample:\")\n",
    "print(sample_2c['query'].unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadfa4d",
   "metadata": {},
   "source": [
    "### Some Data Explroing\n",
    "\n",
    "Intresting queires: One query was  \"usb2aub2ra1m\"\n",
    "\n",
    "And its apprently a product id for right anlged usb connector\n",
    "\n",
    "https://www.startech.com/en-eu/cables/usb2aub2ra1m?srsltid=AfmBOoryvB93OxhVQnPUAocknMNz41MVDvr2TJMrWf0ijRnCwf5htlXn\n",
    "\n",
    "Face urine? - Fake urine but still never knew these existed haha\n",
    "\n",
    "And some plumbing related queires: zurn qkipsp 5 port plastic manifold without valves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b6289",
   "metadata": {},
   "source": [
    "# Step 3: Vector Index\n",
    "\n",
    "3a - Baseline tf-idf \n",
    "\n",
    "3b - Dense model (all-MiniLM-L6-v2)\n",
    "\n",
    "3c - Re-ranking model Hybrid model\n",
    "\n",
    "3d - Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca474a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- TF-IDF & Sparse Retrieval ---\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# --- Dense Retrieval (SentenceTransformers & ChromaDB) ---\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import chromadb\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "RANDOM_STATE = 42\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "# Model Names\n",
    "RETRIEVAL_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "RERANKER_MODEL_NAME = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "TWO_TOWER_MODEL_PATH = './two_tower_model' # Or './two_tower_model_corrected'\n",
    "\n",
    "# DB Paths\n",
    "DB_PATH = \"./chroma_data\"\n",
    "COLLECTION_NAME = \"product_embeddings\"\n",
    "\n",
    "# File Paths\n",
    "SAMPLED_DATA_CSV = r'/Users/ashrithgrandi/Desktop/Grainger/dataset/sample_2c_full_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bf6adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_locale</th>\n",
       "      <th>esci_label</th>\n",
       "      <th>small_version</th>\n",
       "      <th>large_version</th>\n",
       "      <th>split</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_bullet_point</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118060</td>\n",
       "      <td>6 dining chairs</td>\n",
       "      <td>4845</td>\n",
       "      <td>B08CZ6TC2L</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Yaheetech Dining Chairs Velvet Armchairs for C...</td>\n",
       "      <td>Set of 6 Kitchen Dining Chairs for Counter Lou...</td>\n",
       "      <td>STRONG METAL LEGS: To enhance the weight capac...</td>\n",
       "      <td>Yaheetech</td>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118064</td>\n",
       "      <td>6 dining chairs</td>\n",
       "      <td>4845</td>\n",
       "      <td>B08HQG1MFS</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>CozyCasa Dining Chairs Modern Style Dining Cha...</td>\n",
       "      <td>&lt;b&gt;If you are in search of some quality-reliab...</td>\n",
       "      <td>Dining Chairs set of 6 -- White PP backrest an...</td>\n",
       "      <td>CozyCasa</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118065</td>\n",
       "      <td>6 dining chairs</td>\n",
       "      <td>4845</td>\n",
       "      <td>B08K2K3J4C</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Yaheetech Dining Chairs with Waterproof leathe...</td>\n",
       "      <td>Make every long-time sitting comfortable. The ...</td>\n",
       "      <td>MULTIPLE USE: Sold in a set of 6 chairs. Desig...</td>\n",
       "      <td>Yaheetech</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118066</td>\n",
       "      <td>6 dining chairs</td>\n",
       "      <td>4845</td>\n",
       "      <td>B08K2V66N8</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Yaheetech Dining Chairs Dining Room Chairs Liv...</td>\n",
       "      <td>Make every dinner time comfortable. Constructe...</td>\n",
       "      <td>MULTIPLE USE: Sold in a set of 6 chairs. This ...</td>\n",
       "      <td>Yaheetech</td>\n",
       "      <td>Khaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118067</td>\n",
       "      <td>6 dining chairs</td>\n",
       "      <td>4845</td>\n",
       "      <td>B08K8VDTW8</td>\n",
       "      <td>us</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>Modern Dining Chairs Set of 6 - Faux Leather D...</td>\n",
       "      <td>&lt;b&gt;Modern Dining Chairs Set of 6 - Faux Leathe...</td>\n",
       "      <td>Comfortable Dining Chairs Set of 6 - The dinin...</td>\n",
       "      <td>WENYU</td>\n",
       "      <td>Grey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id            query  query_id  product_id product_locale  \\\n",
       "0      118060  6 dining chairs      4845  B08CZ6TC2L             us   \n",
       "1      118064  6 dining chairs      4845  B08HQG1MFS             us   \n",
       "2      118065  6 dining chairs      4845  B08K2K3J4C             us   \n",
       "3      118066  6 dining chairs      4845  B08K2V66N8             us   \n",
       "4      118067  6 dining chairs      4845  B08K8VDTW8             us   \n",
       "\n",
       "  esci_label  small_version  large_version  split  \\\n",
       "0          E              1              1  train   \n",
       "1          E              1              1  train   \n",
       "2          E              1              1  train   \n",
       "3          E              1              1  train   \n",
       "4          E              1              1  train   \n",
       "\n",
       "                                       product_title  \\\n",
       "0  Yaheetech Dining Chairs Velvet Armchairs for C...   \n",
       "1  CozyCasa Dining Chairs Modern Style Dining Cha...   \n",
       "2  Yaheetech Dining Chairs with Waterproof leathe...   \n",
       "3  Yaheetech Dining Chairs Dining Room Chairs Liv...   \n",
       "4  Modern Dining Chairs Set of 6 - Faux Leather D...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  Set of 6 Kitchen Dining Chairs for Counter Lou...   \n",
       "1  <b>If you are in search of some quality-reliab...   \n",
       "2  Make every long-time sitting comfortable. The ...   \n",
       "3  Make every dinner time comfortable. Constructe...   \n",
       "4  <b>Modern Dining Chairs Set of 6 - Faux Leathe...   \n",
       "\n",
       "                                product_bullet_point product_brand  \\\n",
       "0  STRONG METAL LEGS: To enhance the weight capac...     Yaheetech   \n",
       "1  Dining Chairs set of 6 -- White PP backrest an...      CozyCasa   \n",
       "2  MULTIPLE USE: Sold in a set of 6 chairs. Desig...     Yaheetech   \n",
       "3  MULTIPLE USE: Sold in a set of 6 chairs. This ...     Yaheetech   \n",
       "4  Comfortable Dining Chairs Set of 6 - The dinin...         WENYU   \n",
       "\n",
       "  product_color  \n",
       "0          Grey  \n",
       "1         White  \n",
       "2         Brown  \n",
       "3         Khaki  \n",
       "4          Grey  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the stored dataset\n",
    "df_sample = pd.read_csv(SAMPLED_DATA_CSV)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde9408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data into a unique Product Corpus...\n",
      "Created corpus of 485 unique products.\n",
      "Created evaluation set of 485 query-product pairs.\n",
      "Created ground truth map for 50 unique queries.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing data into a unique Product Corpus...\")\n",
    "product_columns = [\n",
    "    'product_id', \n",
    "    'product_title', \n",
    "    'product_description', \n",
    "    'product_bullet_point', \n",
    "    'product_brand', \n",
    "    'product_color'\n",
    "]\n",
    "product_corpus_df = df_sample[product_columns].drop_duplicates(subset=['product_id']).reset_index(drop=True)\n",
    "\n",
    "# Fill NaNs and combine text fields\n",
    "text_cols_to_fill = product_columns[1:]\n",
    "for col in text_cols_to_fill:\n",
    "    product_corpus_df[col] = product_corpus_df[col].fillna('')\n",
    "\n",
    "product_corpus_df['product_text'] = (\n",
    "    product_corpus_df['product_title'] + ' ' +\n",
    "    product_corpus_df['product_brand'] + ' ' +\n",
    "    product_corpus_df['product_color'] + ' ' +\n",
    "    product_corpus_df['product_description'] + ' ' +\n",
    "    product_corpus_df['product_bullet_point']\n",
    ")\n",
    "product_corpus_df['product_text'] = product_corpus_df['product_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(f\"Created corpus of {len(product_corpus_df)} unique products.\")\n",
    "\n",
    "# --- 2. Create Query Evaluation Set (Ground Truth) ---\n",
    "query_eval_set = df_sample[['query', 'query_id', 'product_id', 'esci_label']].copy()\n",
    "print(f\"Created evaluation set of {len(query_eval_set)} query-product pairs.\")\n",
    "\n",
    "# Create a ground truth map: {query -> list_of_relevant_product_ids}\n",
    "ground_truth_map = query_eval_set.groupby('query')['product_id'].apply(list).to_dict()\n",
    "unique_queries_to_eval = list(ground_truth_map.keys())\n",
    "print(f\"Created ground truth map for {len(unique_queries_to_eval)} unique queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae17ca7",
   "metadata": {},
   "source": [
    "## 3a: tf-idf\n",
    "\n",
    "In this section i created an TF-IDF sparse vector from the combined product text (title, brand, color, description, bullets), limits to the top 5000 terms.\n",
    "\n",
    "To test, we used an cosine-similarity index (NearestNeighbors) to serve as a sparse retrieval baseline\n",
    "\n",
    "- TF-IDF will struggle with synonyms and paraphrases where semantic similarity is required.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600a6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Model 1: TF-IDF ---\n",
      "TF-IDF matrix created with shape: (485, 5000)\n",
      "In-memory sparse TF-IDF index built successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Building Model 1: TF-IDF ---\")\n",
    "documents_list = product_corpus_df['product_text'].tolist()\n",
    "\n",
    "# Initialize and fit the vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents_list)\n",
    "print(f\"TF-IDF matrix created with shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Build the NearestNeighbors index\n",
    "n_neighbors_k = 50 # Retrieve 50 candidates for evaluation\n",
    "nn_index_tfidf = NearestNeighbors(n_neighbors=n_neighbors_k, metric='cosine', algorithm='brute')\n",
    "nn_index_tfidf.fit(tfidf_matrix)\n",
    "print(\"In-memory sparse TF-IDF index built successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df319cc",
   "metadata": {},
   "source": [
    "## 3b: Dense model (all-MiniLM-L6-v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4d6030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Building Model 2: Dense Retrieval (all-MiniLM-L6-v2) ---\n",
      "Retrieval model loaded.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Building Model 2: Dense Retrieval ({RETRIEVAL_MODEL_NAME}) ---\")\n",
    "\n",
    "# Load the retrieval model\n",
    "retrieval_model = SentenceTransformer(RETRIEVAL_MODEL_NAME)\n",
    "print(\"Retrieval model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bd48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 485 documents for ChromaDB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921d51529fc34da9bb22530d44412363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated.\n",
      "Successfully created ChromaDB collection with 485 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Embed all documents in the corpus\n",
    "print(f\"Embedding {len(product_corpus_df)} documents for ChromaDB...\")\n",
    "doc_embeddings = retrieval_model.encode(\n",
    "    product_corpus_df['product_text'].tolist(), \n",
    "    show_progress_bar=True\n",
    ")\n",
    "print(\"Embeddings generated.\")\n",
    "\n",
    "# Create and populate the ChromaDB collection\n",
    "if os.path.exists(DB_PATH):\n",
    "    shutil.rmtree(DB_PATH)\n",
    "client = chromadb.PersistentClient(path=DB_PATH)\n",
    "\n",
    "collection_dense = client.get_or_create_collection(\n",
    "    name=COLLECTION_NAME, \n",
    "    metadata={\"hnsw:space\": \"l2\"} # Using 'l2' (Euclidean) distance\n",
    ")\n",
    "\n",
    "# Prepare data for Chroma\n",
    "product_ids_str = product_corpus_df['product_id'].astype(str).tolist()\n",
    "metadatas_list = product_corpus_df.to_dict('records')\n",
    "\n",
    "collection_dense.add(\n",
    "    embeddings=doc_embeddings.tolist(),\n",
    "    metadatas=metadatas_list,\n",
    "    ids=product_ids_str\n",
    ")\n",
    "print(f\"Successfully created ChromaDB collection with {collection_dense.count()} vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa8aeb",
   "metadata": {},
   "source": [
    "## Re-ranking (Cross-Encoder)\n",
    "\n",
    "We load the `ms-marco-MiniLM-L-6-v2` Cross-Encoder. This model doesn't need an index; it scores `(query, document)` pairs provided by a retrieval model (like Model 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f14dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Model 3: Re-Ranker (cross-encoder/ms-marco-MiniLM-L-6-v2) ---\n",
      "Re-ranking model loaded.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Loading Model 3: Re-Ranker ({RERANKER_MODEL_NAME}) ---\")\n",
    "cross_encoder_model = CrossEncoder(RERANKER_MODEL_NAME)\n",
    "print(\"Re-ranking model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cee19",
   "metadata": {},
   "source": [
    "# Section 6: Comparative Evaluation\n",
    "\n",
    "Looping through all 50 unique queries from our ground truth set and run them against all available models to compare their performance fairly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30cabd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation for 50 unique queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1599d5a5994e2a906b4bbb13223f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating All Models:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics_for_query(retrieved_ids, ground_truth_ids):\n",
    "    \"\"\"Calculates Recall@k and MRR for a single query's results.\"\"\"\n",
    "    ground_truth_set = set(ground_truth_ids)\n",
    "    if not ground_truth_set:\n",
    "        return 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    # Calculate Recall@k\n",
    "    retrieved_at_1 = set(retrieved_ids[:1])\n",
    "    retrieved_at_5 = set(retrieved_ids[:5])\n",
    "    retrieved_at_10 = set(retrieved_ids[:10])\n",
    "    \n",
    "    recall_at_1 = len(ground_truth_set.intersection(retrieved_at_1)) / len(ground_truth_set)\n",
    "    recall_at_5 = len(ground_truth_set.intersection(retrieved_at_5)) / len(ground_truth_set)\n",
    "    recall_at_10 = len(ground_truth_set.intersection(retrieved_at_10)) / len(ground_truth_set)\n",
    "\n",
    "    # Calculate MRR (based on all relevant items, as in your original cell 32)\n",
    "    mrr_robust = 0.0\n",
    "    for gt_id in ground_truth_ids:\n",
    "        if gt_id in retrieved_ids:\n",
    "            try:\n",
    "                rank_robust = retrieved_ids.index(gt_id) + 1\n",
    "                mrr_robust += 1.0 / rank_robust\n",
    "            except ValueError:\n",
    "                continue # Should not happen if gt_id in retrieved_ids\n",
    "                \n",
    "    mrr_robust = mrr_robust / len(ground_truth_ids)\n",
    "\n",
    "    return recall_at_1, recall_at_5, recall_at_10, mrr_robust\n",
    "\n",
    "# --- Main Evaluation Loop ---\n",
    "\n",
    "print(f\"Starting evaluation for {len(unique_queries_to_eval)} unique queries...\")\n",
    "\n",
    "# We will retrieve 50 candidates for re-ranking\n",
    "N_CANDIDATES = 50 \n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query in tqdm(unique_queries_to_eval, desc=\"Evaluating All Models\"):\n",
    "    ground_truth_ids = ground_truth_map.get(query, [])\n",
    "    if not ground_truth_ids:\n",
    "        continue\n",
    "    \n",
    "    # --- 1. TF-IDF Evaluation ---\n",
    "    query_vector_sparse = tfidf_vectorizer.transform([query])\n",
    "    distances, indices = nn_index_tfidf.kneighbors(query_vector_sparse, n_neighbors=N_CANDIDATES)\n",
    "    tfidf_retrieved_ids = product_corpus_df.iloc[indices[0]]['product_id'].tolist()\n",
    "    \n",
    "    r1, r5, r10, mrr = calculate_metrics_for_query(tfidf_retrieved_ids, ground_truth_ids)\n",
    "    all_results.append({\n",
    "        \"Model\": \"1. TF-IDF\",\n",
    "        \"Query\": query,\n",
    "        \"Recall@1\": r1,\n",
    "        \"Recall@5\": r5,\n",
    "        \"Recall@10\": r10,\n",
    "        \"MRR\": mrr\n",
    "    })\n",
    "\n",
    "    # --- 2. Dense Model Evaluation ---\n",
    "    query_vector_dense = retrieval_model.encode([query]).tolist()\n",
    "    search_results = collection_dense.query(\n",
    "        query_embeddings=query_vector_dense,\n",
    "        n_results=N_CANDIDATES,\n",
    "    )\n",
    "    dense_retrieved_ids = [meta['product_id'] for meta in search_results['metadatas'][0]]\n",
    "    \n",
    "    r1, r5, r10, mrr = calculate_metrics_for_query(dense_retrieved_ids, ground_truth_ids)\n",
    "    all_results.append({\n",
    "        \"Model\": \"2. Dense (S-BERT)\",\n",
    "        \"Query\": query,\n",
    "        \"Recall@1\": r1,\n",
    "        \"Recall@5\": r5,\n",
    "        \"Recall@10\": r10,\n",
    "        \"MRR\": mrr\n",
    "    })\n",
    "\n",
    "    # --- 3. Re-Ranker Evaluation ---\n",
    "    if cross_encoder_model:\n",
    "        # We re-rank the candidates from the Dense model\n",
    "        candidate_texts = []\n",
    "        for pid in dense_retrieved_ids:\n",
    "            try:\n",
    "                text = product_corpus_df.loc[product_corpus_df['product_id'] == pid, 'product_text'].iloc[0]\n",
    "                candidate_texts.append(text)\n",
    "            except IndexError:\n",
    "                candidate_texts.append(\"\") # Append empty string if product_id not found\n",
    "\n",
    "        rerank_pairs = [(query, doc_text) for doc_text in candidate_texts]\n",
    "        rerank_scores = cross_encoder_model.predict(rerank_pairs, show_progress_bar=False)\n",
    "        \n",
    "        reranked_results = list(zip(dense_retrieved_ids, rerank_scores))\n",
    "        reranked_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        reranked_retrieved_ids = [p_id for p_id, score in reranked_results]\n",
    "\n",
    "        r1, r5, r10, mrr = calculate_metrics_for_query(reranked_retrieved_ids, ground_truth_ids)\n",
    "        all_results.append({\n",
    "            \"Model\": \"3. Re-Ranker\",\n",
    "            \"Query\": query,\n",
    "            \"Recall@1\": r1,\n",
    "            \"Recall@5\": r5,\n",
    "            \"Recall@10\": r10,\n",
    "            \"MRR\": mrr\n",
    "        })\n",
    "\n",
    "print(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b03e3c",
   "metadata": {},
   "source": [
    "## Section 7: Final Results\n",
    "\n",
    "Here is the final comparison of all models across the entire 50-query evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9baedb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Aggregate Model Performance (Averaged over 50 Queries) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Avg_Rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. TF-IDF</th>\n",
       "      <td>0.130202</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>0.690149</td>\n",
       "      <td>0.292254</td>\n",
       "      <td>3.421686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Dense (S-BERT)</th>\n",
       "      <td>0.136868</td>\n",
       "      <td>0.554220</td>\n",
       "      <td>0.748343</td>\n",
       "      <td>0.319586</td>\n",
       "      <td>3.129052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. Re-Ranker</th>\n",
       "      <td>0.138118</td>\n",
       "      <td>0.564091</td>\n",
       "      <td>0.785804</td>\n",
       "      <td>0.323647</td>\n",
       "      <td>3.089782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Recall@1  Recall@5  Recall@10       MRR  Avg_Rank\n",
       "Model                                                               \n",
       "1. TF-IDF          0.130202  0.503778   0.690149  0.292254  3.421686\n",
       "2. Dense (S-BERT)  0.136868  0.554220   0.748343  0.319586  3.129052\n",
       "3. Re-Ranker       0.138118  0.564091   0.785804  0.323647  3.089782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results_all = pd.DataFrame(all_results)\n",
    "\n",
    "df_summary = df_results_all.groupby('Model')[['Recall@1', 'Recall@5', 'Recall@10', 'MRR']].mean().sort_values(by=\"Model\")\n",
    "\n",
    "# Calculate average rank (1/MRR gives approximate average rank)\n",
    "df_summary['Avg_Rank'] = 1 / df_summary['MRR']\n",
    "\n",
    "print(\"--- Aggregate Model Performance (Averaged over 50 Queries) ---\")\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658900b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Per-Query Performance Breakdown (by MRR) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>1. TF-IDF</th>\n",
       "      <th>2. Dense (S-BERT)</th>\n",
       "      <th>3. Re-Ranker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6 dining chairs</th>\n",
       "      <td>0.166987</td>\n",
       "      <td>0.159189</td>\n",
       "      <td>0.166538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a intex pool pump</th>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activated carbon mask</th>\n",
       "      <td>0.280489</td>\n",
       "      <td>0.291988</td>\n",
       "      <td>0.292897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adidas original superstar women</th>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balloons yellow and orange</th>\n",
       "      <td>0.202327</td>\n",
       "      <td>0.202327</td>\n",
       "      <td>0.202327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big little lies</th>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.357639</td>\n",
       "      <td>0.358796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brumate hopsulator slim</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carpenter bench press</th>\n",
       "      <td>0.287649</td>\n",
       "      <td>0.331503</td>\n",
       "      <td>0.314748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christmas dresses size 3t-4t</th>\n",
       "      <td>0.237834</td>\n",
       "      <td>0.237943</td>\n",
       "      <td>0.240380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computers</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.205811</td>\n",
       "      <td>0.216783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cow utter balm</th>\n",
       "      <td>0.266270</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daisy buck</th>\n",
       "      <td>0.370408</td>\n",
       "      <td>0.365873</td>\n",
       "      <td>0.370408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dive light</th>\n",
       "      <td>0.227337</td>\n",
       "      <td>0.244626</td>\n",
       "      <td>0.244626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama book</th>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethique perfector</th>\n",
       "      <td>0.274534</td>\n",
       "      <td>0.200522</td>\n",
       "      <td>0.257179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face urine for drug test</th>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.307716</td>\n",
       "      <td>0.285287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fathes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.008586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiberglass sealer</th>\n",
       "      <td>0.291988</td>\n",
       "      <td>0.290877</td>\n",
       "      <td>0.285838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming chair with footrest and speakers</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incase macbook air 13 inch case</th>\n",
       "      <td>0.258067</td>\n",
       "      <td>0.242567</td>\n",
       "      <td>0.257435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jack skellington beanie</th>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.371528</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeans for men slim fit 29x28</th>\n",
       "      <td>0.311552</td>\n",
       "      <td>0.312085</td>\n",
       "      <td>0.314330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kay correll sweet river series</th>\n",
       "      <td>0.370408</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.370408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logitech g933</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long sweater</th>\n",
       "      <td>0.204398</td>\n",
       "      <td>0.249675</td>\n",
       "      <td>0.249838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac book pro 13 cover</th>\n",
       "      <td>0.182480</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.404365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nathan vaporair 7l 2.0</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pa4 micrpphone prime</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320086</td>\n",
       "      <td>0.327232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinhole glasses</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.382576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plants</th>\n",
       "      <td>0.153354</td>\n",
       "      <td>0.163562</td>\n",
       "      <td>0.167197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poleras deportivas mujer</th>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainbow brite costume women</th>\n",
       "      <td>0.289563</td>\n",
       "      <td>0.283968</td>\n",
       "      <td>0.292897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red bows for crafts</th>\n",
       "      <td>0.244203</td>\n",
       "      <td>0.244626</td>\n",
       "      <td>0.244626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saucony jazz mens olive</th>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spotify with alexa</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square table with chairs</th>\n",
       "      <td>0.256132</td>\n",
       "      <td>0.175589</td>\n",
       "      <td>0.295883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stephenie meyer the seeker</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434524</td>\n",
       "      <td>0.431098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tan and brown bathroom wall decor</th>\n",
       "      <td>0.168674</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.171620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the chalice and the blade by riane eisler</th>\n",
       "      <td>0.380556</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.380556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the theory that would not die</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.344444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turning shoe</th>\n",
       "      <td>0.128128</td>\n",
       "      <td>0.129347</td>\n",
       "      <td>0.128965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usb2aub2ra1m</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanity table without mirror with drawers</th>\n",
       "      <td>0.314330</td>\n",
       "      <td>0.314330</td>\n",
       "      <td>0.314330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibration sensor connect to phone</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather theme cutout</th>\n",
       "      <td>0.190289</td>\n",
       "      <td>0.221233</td>\n",
       "      <td>0.212834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter ski half mask</th>\n",
       "      <td>0.205286</td>\n",
       "      <td>0.244203</td>\n",
       "      <td>0.244626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womens sport sweatpants</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>0.420922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xtc the big express</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.229167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeti tall thin can cooler</th>\n",
       "      <td>0.199544</td>\n",
       "      <td>0.202343</td>\n",
       "      <td>0.148344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurn qkipsp 5 port plastic manifold without valves</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.467593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                                               1. TF-IDF  \\\n",
       "Query                                                           \n",
       "6 dining chairs                                      0.166987   \n",
       "a intex pool pump                                    0.408333   \n",
       "activated carbon mask                                0.280489   \n",
       "adidas original superstar women                      0.408333   \n",
       "balloons yellow and orange                           0.202327   \n",
       "big little lies                                      0.313131   \n",
       "brumate hopsulator slim                              0.611111   \n",
       "carpenter bench press                                0.287649   \n",
       "christmas dresses size 3t-4t                         0.237834   \n",
       "computers                                            0.100000   \n",
       "cow utter balm                                       0.266270   \n",
       "daisy buck                                           0.370408   \n",
       "dive light                                           0.227337   \n",
       "drama book                                           0.325000   \n",
       "ethique perfector                                    0.274534   \n",
       "face urine for drug test                             0.272222   \n",
       "fathes                                               0.000000   \n",
       "fiberglass sealer                                    0.291988   \n",
       "gaming chair with footrest and speakers              0.520833   \n",
       "incase macbook air 13 inch case                      0.258067   \n",
       "jack skellington beanie                              0.408333   \n",
       "jeans for men slim fit 29x28                         0.311552   \n",
       "kay correll sweet river series                       0.370408   \n",
       "logitech g933                                        0.520833   \n",
       "long sweater                                         0.204398   \n",
       "mac book pro 13 cover                                0.182480   \n",
       "nathan vaporair 7l 2.0                               0.520833   \n",
       "pa4 micrpphone prime                                 0.000000   \n",
       "pinhole glasses                                      0.375000   \n",
       "plants                                               0.153354   \n",
       "poleras deportivas mujer                             0.015928   \n",
       "rainbow brite costume women                          0.289563   \n",
       "red bows for crafts                                  0.244203   \n",
       "saucony jazz mens olive                              0.520833   \n",
       "spotify with alexa                                   0.500000   \n",
       "square table with chairs                             0.256132   \n",
       "stephenie meyer the seeker                           0.375000   \n",
       "tan and brown bathroom wall decor                    0.168674   \n",
       "the chalice and the blade by riane eisler            0.380556   \n",
       "the theory that would not die                        0.333333   \n",
       "turning shoe                                         0.128128   \n",
       "usb2aub2ra1m                                         0.000000   \n",
       "vanity table without mirror with drawers             0.314330   \n",
       "vibration sensor connect to phone                    0.583333   \n",
       "weather theme cutout                                 0.190289   \n",
       "winter ski half mask                                 0.205286   \n",
       "womens sport sweatpants                              0.350000   \n",
       "xtc the big express                                  0.229167   \n",
       "yeti tall thin can cooler                            0.199544   \n",
       "zurn qkipsp 5 port plastic manifold without valves   0.458333   \n",
       "\n",
       "Model                                               2. Dense (S-BERT)  \\\n",
       "Query                                                                   \n",
       "6 dining chairs                                              0.159189   \n",
       "a intex pool pump                                            0.408333   \n",
       "activated carbon mask                                        0.291988   \n",
       "adidas original superstar women                              0.408333   \n",
       "balloons yellow and orange                                   0.202327   \n",
       "big little lies                                              0.357639   \n",
       "brumate hopsulator slim                                      0.611111   \n",
       "carpenter bench press                                        0.331503   \n",
       "christmas dresses size 3t-4t                                 0.237943   \n",
       "computers                                                    0.205811   \n",
       "cow utter balm                                               0.271617   \n",
       "daisy buck                                                   0.365873   \n",
       "dive light                                                   0.244626   \n",
       "drama book                                                   0.375000   \n",
       "ethique perfector                                            0.200522   \n",
       "face urine for drug test                                     0.307716   \n",
       "fathes                                                       0.013462   \n",
       "fiberglass sealer                                            0.290877   \n",
       "gaming chair with footrest and speakers                      0.520833   \n",
       "incase macbook air 13 inch case                              0.242567   \n",
       "jack skellington beanie                                      0.371528   \n",
       "jeans for men slim fit 29x28                                 0.312085   \n",
       "kay correll sweet river series                               0.361905   \n",
       "logitech g933                                                0.520833   \n",
       "long sweater                                                 0.249675   \n",
       "mac book pro 13 cover                                        0.372222   \n",
       "nathan vaporair 7l 2.0                                       0.520833   \n",
       "pa4 micrpphone prime                                         0.320086   \n",
       "pinhole glasses                                              0.394444   \n",
       "plants                                                       0.163562   \n",
       "poleras deportivas mujer                                     0.005263   \n",
       "rainbow brite costume women                                  0.283968   \n",
       "red bows for crafts                                          0.244626   \n",
       "saucony jazz mens olive                                      0.520833   \n",
       "spotify with alexa                                           0.583333   \n",
       "square table with chairs                                     0.175589   \n",
       "stephenie meyer the seeker                                   0.434524   \n",
       "tan and brown bathroom wall decor                            0.169492   \n",
       "the chalice and the blade by riane eisler                    0.375000   \n",
       "the theory that would not die                                0.315000   \n",
       "turning shoe                                                 0.129347   \n",
       "usb2aub2ra1m                                                 0.408333   \n",
       "vanity table without mirror with drawers                     0.314330   \n",
       "vibration sensor connect to phone                            0.611111   \n",
       "weather theme cutout                                         0.221233   \n",
       "winter ski half mask                                         0.244203   \n",
       "womens sport sweatpants                                      0.377143   \n",
       "xtc the big express                                          0.229167   \n",
       "yeti tall thin can cooler                                    0.202343   \n",
       "zurn qkipsp 5 port plastic manifold without valves           0.500000   \n",
       "\n",
       "Model                                               3. Re-Ranker  \n",
       "Query                                                             \n",
       "6 dining chairs                                         0.166538  \n",
       "a intex pool pump                                       0.408333  \n",
       "activated carbon mask                                   0.292897  \n",
       "adidas original superstar women                         0.408333  \n",
       "balloons yellow and orange                              0.202327  \n",
       "big little lies                                         0.358796  \n",
       "brumate hopsulator slim                                 0.611111  \n",
       "carpenter bench press                                   0.314748  \n",
       "christmas dresses size 3t-4t                            0.240380  \n",
       "computers                                               0.216783  \n",
       "cow utter balm                                          0.269300  \n",
       "daisy buck                                              0.370408  \n",
       "dive light                                              0.244626  \n",
       "drama book                                              0.408333  \n",
       "ethique perfector                                       0.257179  \n",
       "face urine for drug test                                0.285287  \n",
       "fathes                                                  0.008586  \n",
       "fiberglass sealer                                       0.285838  \n",
       "gaming chair with footrest and speakers                 0.520833  \n",
       "incase macbook air 13 inch case                         0.257435  \n",
       "jack skellington beanie                                 0.408333  \n",
       "jeans for men slim fit 29x28                            0.314330  \n",
       "kay correll sweet river series                          0.370408  \n",
       "logitech g933                                           0.520833  \n",
       "long sweater                                            0.249838  \n",
       "mac book pro 13 cover                                   0.404365  \n",
       "nathan vaporair 7l 2.0                                  0.520833  \n",
       "pa4 micrpphone prime                                    0.327232  \n",
       "pinhole glasses                                         0.382576  \n",
       "plants                                                  0.167197  \n",
       "poleras deportivas mujer                                0.003509  \n",
       "rainbow brite costume women                             0.292897  \n",
       "red bows for crafts                                     0.244626  \n",
       "saucony jazz mens olive                                 0.520833  \n",
       "spotify with alexa                                      0.516667  \n",
       "square table with chairs                                0.295883  \n",
       "stephenie meyer the seeker                              0.431098  \n",
       "tan and brown bathroom wall decor                       0.171620  \n",
       "the chalice and the blade by riane eisler               0.380556  \n",
       "the theory that would not die                           0.344444  \n",
       "turning shoe                                            0.128965  \n",
       "usb2aub2ra1m                                            0.408333  \n",
       "vanity table without mirror with drawers                0.314330  \n",
       "vibration sensor connect to phone                       0.611111  \n",
       "weather theme cutout                                    0.212834  \n",
       "winter ski half mask                                    0.244626  \n",
       "womens sport sweatpants                                 0.420922  \n",
       "xtc the big express                                     0.229167  \n",
       "yeti tall thin can cooler                               0.148344  \n",
       "zurn qkipsp 5 port plastic manifold without valves      0.467593  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display Per-Query Results for Analysis ---\n",
    "\n",
    "print(\"\\n--- Per-Query Performance Breakdown (by MRR) ---\")\n",
    "pd.set_option('display.max_rows', 100)\n",
    "try:\n",
    "    display(df_results_all.pivot(index=\"Query\", columns=\"Model\", values=\"MRR\"))\n",
    "except Exception as e:\n",
    "    print(f\"Could not pivot results: {e}\")\n",
    "    print(\"Displaying raw results instead:\")\n",
    "    display(df_results_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db84baa",
   "metadata": {},
   "source": [
    "## Single Query testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5efb9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Query: 'carpenter bench press'\n",
      "Ground Truth 'Exact' Product IDs (8): ['B088R8VC7V', 'B07N4QN64D', 'B01M4F8JZJ', 'B01LZV1QW1', 'B00HQONFVE', 'B00BHSPJC8', 'B00068U7XQ', 'B00SIQ1DLS']\n",
      "\n",
      "--- TF-IDF Sanity Check ---\n",
      "     product_id  _distance  is_ground_truth  \\\n",
      "73   B01LZV1QW1   0.813588             True   \n",
      "70   B088R8VC7V   0.868601             True   \n",
      "76   B00068U7XQ   0.883066             True   \n",
      "431  B06XD1DVBG   0.885864            False   \n",
      "71   B07N4QN64D   0.893176             True   \n",
      "427  B06XD5G2XB   0.911316            False   \n",
      "77   B00SIQ1DLS   0.912220             True   \n",
      "74   B00HQONFVE   0.916837             True   \n",
      "129  B07G15QZNQ   0.924860            False   \n",
      "342  B0015TX0MU   0.925376            False   \n",
      "\n",
      "                                         product_title  \n",
      "73   Genesis GDP805P 5-Speed 2.6 Amp 8\" Drill Press...  \n",
      "70   Workbench Mounted Drilling Machine, 350W 5 Spe...  \n",
      "76              Palmgren Ratcheting arbor press, 3 ton  \n",
      "431  Creative Teaching Press Safari Friends Calenda...  \n",
      "71   Drill Stand for Hand Drill, Electric Bench Cla...  \n",
      "427  CTP Woodland Friends Calendar Set Bulletin Boa...  \n",
      "77   Yost M7WW Rapid Acting Wood Working Vise, 7\", ...  \n",
      "74   WEN 4208T 2.3-Amp 8-Inch 5-Speed Benchtop Dril...  \n",
      "129  Diving Flashlight 18000 Lumen IPX8 Scuba Dive ...  \n",
      "342  Office Star Table And Chair Set, Light Grey, B...  \n",
      "TF-IDF found 6 out of 8 ground truth items in Top 10.\n",
      "\n",
      "--- Dense Model Sanity Check ---\n",
      "   product_id  _distance  is_ground_truth  \\\n",
      "0  B07N4QN64D   0.949832             True   \n",
      "1  B088R8VC7V   1.055872             True   \n",
      "2  B00HQONFVE   1.058271             True   \n",
      "3  B00068U7XQ   1.136232             True   \n",
      "4  B01LZV1QW1   1.194515             True   \n",
      "5  B00SIQ1DLS   1.298030             True   \n",
      "6  B07HH3K4SK   1.401191            False   \n",
      "7  B01GOM6OUM   1.409457            False   \n",
      "8  B00BHSPJC8   1.445602             True   \n",
      "9  B078WZLFHG   1.452312            False   \n",
      "\n",
      "                                       product_title  \n",
      "0  Drill Stand for Hand Drill, Electric Bench Cla...  \n",
      "1  Workbench Mounted Drilling Machine, 350W 5 Spe...  \n",
      "2  WEN 4208T 2.3-Amp 8-Inch 5-Speed Benchtop Dril...  \n",
      "3             Palmgren Ratcheting arbor press, 3 ton  \n",
      "4  Genesis GDP805P 5-Speed 2.6 Amp 8\" Drill Press...  \n",
      "5  Yost M7WW Rapid Acting Wood Working Vise, 7\", ...  \n",
      "6  Giantex Set of 6 Modern Dining Chairs w/Plasti...  \n",
      "7  Inspirer Studio Set of 6 New 17 inch SeatDepth...  \n",
      "8      Shop Fox D4328 9-Inch Quick Release Wood Vise  \n",
      "9  Signature Design by Ashley Porter Dining Room ...  \n",
      "Dense Model found 7 out of 8 ground truth items in Top 10.\n"
     ]
    }
   ],
   "source": [
    "test_query = \"carpenter bench press\"\n",
    "if test_query in ground_truth_map:\n",
    "    ground_truth_ids_test = ground_truth_map.get(test_query, [])\n",
    "    print(f\"Test Query: '{test_query}'\")\n",
    "    print(f\"Ground Truth 'Exact' Product IDs ({len(ground_truth_ids_test)}): {ground_truth_ids_test}\")\n",
    "\n",
    "    # --- TF-IDF Sanity Check ---\n",
    "    print(\"\\n--- TF-IDF Sanity Check ---\")\n",
    "    query_vector = tfidf_vectorizer.transform([test_query])\n",
    "    distances, indices = nn_index_tfidf.kneighbors(query_vector, n_neighbors=10)\n",
    "    results_df_tfidf = product_corpus_df.iloc[indices[0]].copy()\n",
    "    results_df_tfidf['_distance'] = distances[0]\n",
    "    results_df_tfidf['is_ground_truth'] = results_df_tfidf['product_id'].isin(ground_truth_ids_test)\n",
    "    print(results_df_tfidf[['product_id', '_distance', 'is_ground_truth', 'product_title']])\n",
    "    matches = results_df_tfidf['is_ground_truth'].sum()\n",
    "    print(f\"TF-IDF found {matches} out of {len(ground_truth_ids_test)} ground truth items in Top 10.\")\n",
    "\n",
    "    # --- Dense Model Sanity Check ---\n",
    "    print(\"\\n--- Dense Model Sanity Check ---\")\n",
    "    query_vector = retrieval_model.encode([test_query]).tolist()\n",
    "    search_results = collection_dense.query(\n",
    "        query_embeddings=query_vector,\n",
    "        n_results=10,\n",
    "    )\n",
    "    result_metadatas = search_results['metadatas'][0]\n",
    "    result_distances = search_results['distances'][0]\n",
    "    results_df_dense = pd.DataFrame({\n",
    "        'product_id': [meta['product_id'] for meta in result_metadatas],\n",
    "        '_distance': result_distances\n",
    "    })\n",
    "    results_df_dense['is_ground_truth'] = results_df_dense['product_id'].isin(ground_truth_ids_test)\n",
    "    results_df_dense = results_df_dense.merge(product_corpus_df[['product_id', 'product_title']], on='product_id', how='left')\n",
    "    print(results_df_dense[['product_id', '_distance', 'is_ground_truth', 'product_title']])\n",
    "    matches_dense = results_df_dense['is_ground_truth'].sum()\n",
    "    print(f\"Dense Model found {matches_dense} out of {len(ground_truth_ids_test)} ground truth items in Top 10.\")\n",
    "else:\n",
    "    print(f\"Test query '{test_query}' not found in the sampled dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66471a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031a5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9189d21",
   "metadata": {},
   "source": [
    "# Step 4 Two tower eval vs others\n",
    "\n",
    "Refrence links:\n",
    "\n",
    "Uber blog on two tower arch: https://www.uber.com/blog/innovative-recommendation-applications-using-two-tower-embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Two-Tower Model Evaluation ===\")\n",
    "\n",
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from two_tower_evaluation import TwoTowerEvaluator\n",
    "\n",
    "# Check if model exists - try both possible paths\n",
    "model_paths = ['./two_tower_model', './two_tower_model_corrected']\n",
    "model_path = None\n",
    "\n",
    "for path in model_paths:\n",
    "    if os.path.exists(path):\n",
    "        model_path = path\n",
    "        break\n",
    "\n",
    "if model_path is None:\n",
    "    print(\" Two-Tower model not found. Please train the model first using two_tower_final.py\")\n",
    "    print(\"   Looked for models in:\")\n",
    "    for path in model_paths:\n",
    "        print(f\"   - {path}\")\n",
    "else:\n",
    "    print(f\" Two-Tower model found at: {model_path}\")\n",
    "    print(\"   Starting evaluation...\")\n",
    "    \n",
    "    try:\n",
    "        evaluator = TwoTowerEvaluator(\n",
    "            model_path='./two_tower_model_corrected', \n",
    "            test_data_path='sample_2c_full_data.csv'\n",
    "        )\n",
    "        \n",
    "        # Run evaluation\n",
    "        print(\"\\n Building product embeddings index...\")\n",
    "        evaluator.build_product_index()\n",
    "        \n",
    "        # Test the same query as baselines for comparison\n",
    "        test_query = \"carpenter bench press\"\n",
    "        print(f\"\\n Testing query: '{test_query}'\")\n",
    "        \n",
    "        # Get ground truth for comparison\n",
    "        ground_truth_df = evaluator.eval_data[evaluator.eval_data['query'] == test_query]\n",
    "        ground_truth_ids = set(ground_truth_df[ground_truth_df['esci_label'] == 'E']['product_id'].tolist())\n",
    "        \n",
    "        print(f\" Ground Truth: {len(ground_truth_ids)} relevant products\")\n",
    "        print(f\"    Product IDs: {list(ground_truth_ids)}\")\n",
    "        \n",
    "        # Search using Two-Tower model\n",
    "        results = evaluator.search_products(test_query, top_k=10)\n",
    "        \n",
    "        print(f\"\\n Two-Tower Top-10 Results:\")\n",
    "        hits = 0\n",
    "        for i, (product_id, similarity) in enumerate(results, 1):\n",
    "            is_relevant = product_id in ground_truth_ids\n",
    "            if is_relevant:\n",
    "                hits += 1\n",
    "            \n",
    "            # Get product title\n",
    "            product_title = evaluator.product_corpus[evaluator.product_corpus['product_id'] == product_id]['product_title'].iloc[0]\n",
    "            status = \" RELEVANT\" if is_relevant else \"\"\n",
    "            \n",
    "            print(f\"  {i:2d}. {status} | Sim: {similarity:.4f} | {product_title[:60]}...\")\n",
    "        \n",
    "        two_tower_precision = hits / 10\n",
    "        two_tower_recall = hits / len(ground_truth_ids) if ground_truth_ids else 0\n",
    "        \n",
    "        print(f\"\\n Two-Tower Results:\")\n",
    "        print(f\"    Precision@10: {two_tower_precision:.4f}\")\n",
    "        print(f\"    Recall@10: {two_tower_recall:.4f}\")\n",
    "        print(f\"    Found {hits} out of {len(ground_truth_ids)} ground truth items in Top 10\")\n",
    "        \n",
    "        # Compare with previous results\n",
    "        print(f\"\\n Comparison Summary:\")\n",
    "        print(f\"    TF-IDF:              Found 6/8 ground truth items (Precision: 0.6000)\")\n",
    "        print(f\"    SentenceTransformers: Found 7/8 ground truth items (Precision: 0.7000)\")\n",
    "        print(f\"    Two-Tower:           Found {hits}/{len(ground_truth_ids)} ground truth items (Precision: {two_tower_precision:.4f})\")\n",
    "        \n",
    "        # Run comprehensive evaluation\n",
    "        print(f\"\\n Running comprehensive evaluation on all test queries...\")\n",
    "        metrics = evaluator.calculate_metrics([1, 5, 10, 20])\n",
    "        avg_metrics, _ = metrics\n",
    "        \n",
    "        print(f\"\\n Comprehensive Results:\")\n",
    "        print(f\"{'Metric':<12} {'Top-1':<8} {'Top-5':<8} {'Top-10':<8} {'Top-20':<8}\")\n",
    "        print(\"-\" * 48)\n",
    "        \n",
    "        for metric_name in ['precision', 'recall', 'ndcg', 'mrr']:\n",
    "            row = f\"{metric_name.upper():<12}\"\n",
    "            for k in [1, 5, 10, 20]:\n",
    "                row += f\"{avg_metrics[k][metric_name]:<8.3f}\"\n",
    "            print(row)\n",
    "        \n",
    "        # Sample additional queries\n",
    "        print(f\"\\n Testing additional sample queries...\")\n",
    "        sample_queries = ['6 dining chairs', 'plants', 'turning shoe']\n",
    "        \n",
    "        for query in sample_queries:\n",
    "            if query in evaluator.eval_data['query'].values:\n",
    "                ground_truth = evaluator.eval_data[evaluator.eval_data['query'] == query]\n",
    "                relevant_count = len(ground_truth[ground_truth['esci_label'] == 'E'])\n",
    "                \n",
    "                results = evaluator.search_products(query, top_k=5)\n",
    "                relevant_in_top5 = sum(1 for pid, _ in results if pid in set(ground_truth[ground_truth['esci_label'] == 'E']['product_id']))\n",
    "                \n",
    "                print(f\"  '{query}': {relevant_in_top5}/{relevant_count} relevant in Top-5\")\n",
    "        \n",
    "        print(f\"\\n Two-Tower evaluation completed!\")\n",
    "        \n",
    "        # Store final metrics for summary\n",
    "        final_precision_10 = avg_metrics[10]['precision']\n",
    "        final_recall_10 = avg_metrics[10]['recall']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error during evaluation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Set default values for summary\n",
    "        final_precision_10 = 0.0\n",
    "        final_recall_10 = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" FINAL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"Method                | Precision@10 | Recall@10 | Notes\")\n",
    "print(\"-\" * 60)\n",
    "print(\"TF-IDF               |    0.6000    |   0.7500  | Sparse, keyword-based\")\n",
    "print(\"SentenceTransformers |    0.7000    |   0.8750  | Dense, pre-trained\")\n",
    "try:\n",
    "    print(f\"Two-Tower (Custom)   |    {final_precision_10:.4f}    |   {final_recall_10:.4f}  | Dense, task-specific\")\n",
    "except:\n",
    "    print(\"Two-Tower (Custom)   |    ?.????    |   ?.????  | Dense, task-specific\")\n",
    "\n",
    "print(\"\\n The Two-Tower model should perform better due to:\")\n",
    "print(\"   - Task-specific training on your exact data\")\n",
    "print(\"   - Separate encoders for queries and products\")\n",
    "print(\"   - Triplet loss optimization for retrieval\")\n",
    "print(\"   - Domain-specific fine-tuning\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
